{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee664430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7a4ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/savannahposner/Desktop/bigProject/Messing_Around.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f3d1a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FID</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>MAG</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>SLAT</th>\n",
       "      <th>SLON</th>\n",
       "      <th>ELAT</th>\n",
       "      <th>ELON</th>\n",
       "      <th>LEN</th>\n",
       "      <th>WID</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Injuries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23025</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>14:35:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020</td>\n",
       "      <td>36.2971</td>\n",
       "      <td>-82.3174</td>\n",
       "      <td>36.2934</td>\n",
       "      <td>-82.3021</td>\n",
       "      <td>0.89</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23027</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075</td>\n",
       "      <td>36.3000</td>\n",
       "      <td>-82.4341</td>\n",
       "      <td>36.3000</td>\n",
       "      <td>-82.4341</td>\n",
       "      <td>3.00</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23028</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>16:08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>36.3037</td>\n",
       "      <td>-82.3923</td>\n",
       "      <td>36.3099</td>\n",
       "      <td>-82.3846</td>\n",
       "      <td>0.61</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23029</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>16:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>36.0424</td>\n",
       "      <td>-82.5568</td>\n",
       "      <td>36.0477</td>\n",
       "      <td>-82.5393</td>\n",
       "      <td>1.04</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>23044</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>19:07:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>36.2255</td>\n",
       "      <td>-83.0570</td>\n",
       "      <td>36.2263</td>\n",
       "      <td>-83.0486</td>\n",
       "      <td>0.50</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1109</td>\n",
       "      <td>28915</td>\n",
       "      <td>1967</td>\n",
       "      <td>7</td>\n",
       "      <td>1967-07-05</td>\n",
       "      <td>14:25:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>-90.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1110</td>\n",
       "      <td>28916</td>\n",
       "      <td>1991</td>\n",
       "      <td>11</td>\n",
       "      <td>1991-11-19</td>\n",
       "      <td>17:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000</td>\n",
       "      <td>35.1300</td>\n",
       "      <td>-90.0200</td>\n",
       "      <td>35.2800</td>\n",
       "      <td>-89.9300</td>\n",
       "      <td>10.00</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1111</td>\n",
       "      <td>28926</td>\n",
       "      <td>1992</td>\n",
       "      <td>3</td>\n",
       "      <td>1992-03-18</td>\n",
       "      <td>08:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>35.2200</td>\n",
       "      <td>-89.7700</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1112</td>\n",
       "      <td>28962</td>\n",
       "      <td>1974</td>\n",
       "      <td>6</td>\n",
       "      <td>1974-06-07</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000</td>\n",
       "      <td>35.5700</td>\n",
       "      <td>-89.6500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1113</td>\n",
       "      <td>28984</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>05:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.180</td>\n",
       "      <td>35.6159</td>\n",
       "      <td>-89.7031</td>\n",
       "      <td>35.6142</td>\n",
       "      <td>-89.6884</td>\n",
       "      <td>0.83</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    FID    YR  MO        DATE      TIME  MAG   LOSS     SLAT  \\\n",
       "0              0  23025  2011   4  2011-04-09  14:35:00    0  0.020  36.2971   \n",
       "1              1  23027  2011   4  2011-04-09  16:00:00    1  0.075  36.3000   \n",
       "2              2  23028  2011   4  2011-04-09  16:08:00    1  0.010  36.3037   \n",
       "3              3  23029  2011   4  2011-04-09  16:15:00    0  0.015  36.0424   \n",
       "4              4  23044  2011   4  2011-04-27  19:07:00    0  0.005  36.2255   \n",
       "...          ...    ...   ...  ..         ...       ...  ...    ...      ...   \n",
       "1109        1109  28915  1967   7  1967-07-05  14:25:00    1  4.000  35.0000   \n",
       "1110        1110  28916  1991  11  1991-11-19  17:05:00    1  6.000  35.1300   \n",
       "1111        1111  28926  1992   3  1992-03-18  08:20:00    0  4.000  35.2200   \n",
       "1112        1112  28962  1974   6  1974-06-07  11:30:00    1  4.000  35.5700   \n",
       "1113        1113  28984  2013   5  2013-05-31  05:05:00    1  0.180  35.6159   \n",
       "\n",
       "         SLON     ELAT     ELON    LEN  WID  Fatalities  Injuries  \n",
       "0    -82.3174  36.2934 -82.3021   0.89   50           0         0  \n",
       "1    -82.4341  36.3000 -82.4341   3.00  150           0         0  \n",
       "2    -82.3923  36.3099 -82.3846   0.61  100           0         0  \n",
       "3    -82.5568  36.0477 -82.5393   1.04   50           0         0  \n",
       "4    -83.0570  36.2263 -83.0486   0.50   70           0         0  \n",
       "...       ...      ...      ...    ...  ...         ...       ...  \n",
       "1109 -90.0000   0.0000   0.0000   0.10   10           0         0  \n",
       "1110 -90.0200  35.2800 -89.9300  10.00   50           0         0  \n",
       "1111 -89.7700   0.0000   0.0000   1.50   50           0         0  \n",
       "1112 -89.6500   0.0000   0.0000   0.30  100           1         1  \n",
       "1113 -89.7031  35.6142 -89.6884   0.83  250           0         0  \n",
       "\n",
       "[1114 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d138115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "\n",
    "target = ''\n",
    "X = pd.get_dummies(df.drop(columns=target))\n",
    "\n",
    "\n",
    "# Create our target\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3203ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1f103",
   "metadata": {},
   "source": [
    "### Run through the Models Provided in the Module 17 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c76ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive random oversampling\n",
      "\n",
      "Confusion Matrix:\n",
      "[[54 17  2  0  2]\n",
      " [49 39 21 11  5]\n",
      " [15 11 14  9  6]\n",
      " [ 2  3  4  5  4]\n",
      " [ 0  1  1  2  2]]\n",
      "\n",
      "The accuracy score: \n",
      "0.37953131313131305\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.45      0.72      0.68      0.55      0.70      0.49        75\n",
      "          1       0.55      0.31      0.79      0.40      0.50      0.24       125\n",
      "          2       0.33      0.25      0.88      0.29      0.47      0.21        55\n",
      "          3       0.19      0.28      0.92      0.22      0.50      0.24        18\n",
      "          4       0.11      0.33      0.94      0.16      0.56      0.29         6\n",
      "\n",
      "avg / total       0.45      0.41      0.79      0.40      0.55      0.30       279\n",
      "\n",
      "SMOTE\n",
      "\n",
      "An Error as occured\n",
      "Random Under Sampler\n",
      "\n",
      "The accuracy score: \n",
      "0.23743030303030302\n",
      "\n",
      "Confusion Matrix:\n",
      "[[46  8 18  3  0  0]\n",
      " [39 49 30  7  0  0]\n",
      " [13 31 10  0  1  0]\n",
      " [ 0 12  4  0  0  2]\n",
      " [ 0  3  2  0  0  1]\n",
      " [ 0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.47      0.61      0.75      0.53      0.68      0.45        75\n",
      "          1       0.48      0.39      0.65      0.43      0.50      0.25       125\n",
      "          2       0.16      0.18      0.76      0.17      0.37      0.13        55\n",
      "          3       0.00      0.00      0.96      0.00      0.00      0.00        18\n",
      "          4       0.00      0.00      1.00      0.00      0.00      0.00         6\n",
      "          5       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.37      0.38      0.72      0.37      0.48      0.26       279\n",
      "\n",
      "SMOTEENN\n",
      "\n",
      "An Error as occured\n",
      "Balanced Random Forest Classifier \n",
      "\n",
      "The accuracy score: \n",
      "0.3527272727272727\n",
      "\n",
      "Confusion Matrix:\n",
      "[[68  7  0  0  0  0]\n",
      " [68 45  9  3  0  0]\n",
      " [18 27  9  1  0  0]\n",
      " [ 3  8  2  3  2  0]\n",
      " [ 0  0  1  3  1  1]\n",
      " [ 0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.43      0.91      0.56      0.59      0.71      0.53        75\n",
      "          1       0.52      0.36      0.73      0.42      0.51      0.25       125\n",
      "          2       0.43      0.16      0.95      0.24      0.39      0.14        55\n",
      "          3       0.30      0.17      0.97      0.21      0.40      0.15        18\n",
      "          4       0.33      0.17      0.99      0.22      0.41      0.15         6\n",
      "          5       0.00      0.00      1.00      0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.46      0.45      0.75      0.41      0.53      0.30       279\n",
      "\n",
      "Easy Ensemble Classifier \n",
      "\n",
      "The accuracy score: \n",
      "0.16524444444444444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6  3  0 16 50]\n",
      " [ 5  3  0 26 91]\n",
      " [ 0  0  0 13 42]\n",
      " [ 0  0  0  1 17]\n",
      " [ 0  0  0  2  4]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.55      0.08      0.98      0.14      0.28      0.07        75\n",
      "          1       0.50      0.02      0.98      0.05      0.15      0.02       125\n",
      "          2       0.00      0.00      1.00      0.00      0.00      0.00        55\n",
      "          3       0.02      0.06      0.78      0.03      0.21      0.04        18\n",
      "          4       0.02      0.67      0.27      0.04      0.42      0.19         6\n",
      "\n",
      "avg / total       0.37      0.05      0.95      0.06      0.17      0.04       279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x =\"An Error as occured\"\n",
    "try:\n",
    "\n",
    "    print(f\"naive random oversampling\\n\")\n",
    "# Resample the training data with the RandomOversampler\n",
    "\n",
    "    ros = RandomOverSampler(random_state=1)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "except:\n",
    "      print(x)\n",
    "\n",
    "\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "try:\n",
    "\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "\n",
    "# Resample the training data with SMOTE\n",
    "    print(f\"SMOTE\\n\")\n",
    "    X_resampled, y_resampled = SMOTE(random_state=1,\n",
    "    sampling_strategy='auto').fit_resample(\n",
    "       X_train, y_train)\n",
    "    Counter(y_resampled)\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "\n",
    "except:\n",
    "      print(x)\n",
    "# Resample the data using the ClusterCentroids resampler\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "# Resample the training data with SMOTE\n",
    "\n",
    "try: \n",
    "    print(f\"Random Under Sampler\\n\")\n",
    "    ros = RandomUnderSampler(random_state=1)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    Counter(y_resampled)\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "except:\n",
    "      print(x)\n",
    "# Resample the training data with SMOTEENN\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "# YOUR CODE HERE\n",
    "try:\n",
    "    print(f\"SMOTEENN\\n\")\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "    Counter(y_resampled)\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "except:  \n",
    "      print(x)\n",
    "\n",
    "\n",
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "try:\n",
    "    print(f\"Balanced Random Forest Classifier \\n\")\n",
    "    model = BalancedRandomForestClassifier(n_estimators =100, random_state=1)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    # Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "except:\n",
    "    print(x)\n",
    "\n",
    "# Train the EasyEnsembleClassifier\n",
    "try:\n",
    "    print(f\"Easy Ensemble Classifier \\n\")\n",
    "\n",
    "# Train the EasyEnsembleClassifier\n",
    "    from imblearn.ensemble import EasyEnsembleClassifier \n",
    "    model = EasyEnsembleClassifier(n_estimators =100, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "    \n",
    "except:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39090f35",
   "metadata": {},
   "source": [
    "### Additional Machine Learning Models that we can try "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af4066",
   "metadata": {},
   "source": [
    "#### SGDClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24d694",
   "metadata": {},
   "source": [
    "link to reference: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbeab8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.2507636363636364\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21 48  6  0  0]\n",
      " [15 99 11  0  0]\n",
      " [ 7 34 10  2  2]\n",
      " [ 0 11  5  0  2]\n",
      " [ 0  4  1  1  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.49      0.28      0.89      0.36      0.50      0.23        75\n",
      "          1       0.51      0.79      0.37      0.62      0.54      0.31       125\n",
      "          2       0.30      0.18      0.90      0.23      0.40      0.15        55\n",
      "          3       0.00      0.00      0.99      0.00      0.00      0.00        18\n",
      "          4       0.00      0.00      0.99      0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.42      0.47      0.67      0.42      0.46      0.23       279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sklearn.linear_model.SGDClassifier\n",
    "\n",
    "\n",
    "# This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: \n",
    "#     the gradient of the loss is estimated each sample at a time and the model is updated \n",
    "#     along the way with a decreasing strength schedule (aka learning rate).\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc0385",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da010d14",
   "metadata": {},
   "source": [
    "link to reference: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b701fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.26202828282828283\n",
      "\n",
      "Confusion Matrix:\n",
      "[[22 13 14 16 10]\n",
      " [19 17 33 23 33]\n",
      " [ 5  4 24  7 15]\n",
      " [ 0  3  4  5  6]\n",
      " [ 0  0  1  4  1]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.48      0.29      0.88      0.36      0.51      0.24        75\n",
      "          1       0.46      0.14      0.87      0.21      0.34      0.11       125\n",
      "          2       0.32      0.44      0.77      0.37      0.58      0.32        55\n",
      "          3       0.09      0.28      0.81      0.14      0.47      0.21        18\n",
      "          4       0.02      0.17      0.77      0.03      0.36      0.12         6\n",
      "\n",
      "avg / total       0.40      0.25      0.85      0.27      0.44      0.19       279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When performing classification you often want to predict not only the class label, \n",
    "# but also the associated probability. \n",
    "# This probability gives you some kind of confidence on the prediction\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)  # GaussianNB itself does not support sample-weights\n",
    "\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abcbe1e",
   "metadata": {},
   "source": [
    " RandomOverSampler: Using differnt solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c2db5",
   "metadata": {},
   "source": [
    "link to reference https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "412e4728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.40687676767676767\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63  8  3  1  0]\n",
      " [53 32 28 11  1]\n",
      " [11 14 18 11  1]\n",
      " [ 0  0 10  5  3]\n",
      " [ 0  0  2  2  2]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.50      0.84      0.69      0.62      0.76      0.59        75\n",
      "          1       0.59      0.26      0.86      0.36      0.47      0.21       125\n",
      "          2       0.30      0.33      0.81      0.31      0.51      0.25        55\n",
      "          3       0.17      0.28      0.90      0.21      0.50      0.24        18\n",
      "          4       0.29      0.33      0.98      0.31      0.57      0.31         6\n",
      "\n",
      "avg / total       0.47      0.43      0.81      0.41      0.56      0.32       279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "    \n",
    "#'liblinearâ€™, â€˜sagâ€™, â€˜saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995dcac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c88383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccdda0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0daf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
