{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee664430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0a1c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a4ae17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>FID</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>MAG</th>\n",
       "      <th>SLAT</th>\n",
       "      <th>SLON</th>\n",
       "      <th>ELAT</th>\n",
       "      <th>ELON</th>\n",
       "      <th>LEN</th>\n",
       "      <th>WID</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Injuries</th>\n",
       "      <th>Property Loss</th>\n",
       "      <th>starting county</th>\n",
       "      <th>ending county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23025</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>14:35:00</td>\n",
       "      <td>0</td>\n",
       "      <td>36.2971</td>\n",
       "      <td>-82.3174</td>\n",
       "      <td>36.2934</td>\n",
       "      <td>-82.3021</td>\n",
       "      <td>0.89</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Carter County</td>\n",
       "      <td>Carter County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23027</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>36.3000</td>\n",
       "      <td>-82.4341</td>\n",
       "      <td>36.3000</td>\n",
       "      <td>-82.4341</td>\n",
       "      <td>3.00</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Washington County</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23028</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>16:08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>36.3037</td>\n",
       "      <td>-82.3923</td>\n",
       "      <td>36.3099</td>\n",
       "      <td>-82.3846</td>\n",
       "      <td>0.61</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Washington County</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23029</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>16:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0424</td>\n",
       "      <td>-82.5568</td>\n",
       "      <td>36.0477</td>\n",
       "      <td>-82.5393</td>\n",
       "      <td>1.04</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Unicoi County</td>\n",
       "      <td>Unicoi County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>23044</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>19:07:00</td>\n",
       "      <td>0</td>\n",
       "      <td>36.2255</td>\n",
       "      <td>-83.0570</td>\n",
       "      <td>36.2263</td>\n",
       "      <td>-83.0486</td>\n",
       "      <td>0.50</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Greene County</td>\n",
       "      <td>Greene County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1109</td>\n",
       "      <td>1109</td>\n",
       "      <td>28915</td>\n",
       "      <td>1967</td>\n",
       "      <td>7</td>\n",
       "      <td>1967-07-05</td>\n",
       "      <td>14:25:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>-90.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Shelby County</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1110</td>\n",
       "      <td>1110</td>\n",
       "      <td>28916</td>\n",
       "      <td>1991</td>\n",
       "      <td>11</td>\n",
       "      <td>1991-11-19</td>\n",
       "      <td>17:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.1300</td>\n",
       "      <td>-90.0200</td>\n",
       "      <td>35.2800</td>\n",
       "      <td>-89.9300</td>\n",
       "      <td>10.00</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Shelby County</td>\n",
       "      <td>Shelby County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1111</td>\n",
       "      <td>1111</td>\n",
       "      <td>28926</td>\n",
       "      <td>1992</td>\n",
       "      <td>3</td>\n",
       "      <td>1992-03-18</td>\n",
       "      <td>08:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>35.2200</td>\n",
       "      <td>-89.7700</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Shelby County</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1112</td>\n",
       "      <td>1112</td>\n",
       "      <td>28962</td>\n",
       "      <td>1974</td>\n",
       "      <td>6</td>\n",
       "      <td>1974-06-07</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.5700</td>\n",
       "      <td>-89.6500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Tipton County</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>28984</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>05:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.6159</td>\n",
       "      <td>-89.7031</td>\n",
       "      <td>35.6142</td>\n",
       "      <td>-89.6884</td>\n",
       "      <td>0.83</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Tipton County</td>\n",
       "      <td>Tipton County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1    FID    YR  MO        DATE      TIME  MAG  \\\n",
       "0              0             0  23025  2011   4  2011-04-09  14:35:00    0   \n",
       "1              1             1  23027  2011   4  2011-04-09  16:00:00    1   \n",
       "2              2             2  23028  2011   4  2011-04-09  16:08:00    1   \n",
       "3              3             3  23029  2011   4  2011-04-09  16:15:00    0   \n",
       "4              4             4  23044  2011   4  2011-04-27  19:07:00    0   \n",
       "...          ...           ...    ...   ...  ..         ...       ...  ...   \n",
       "1109        1109          1109  28915  1967   7  1967-07-05  14:25:00    1   \n",
       "1110        1110          1110  28916  1991  11  1991-11-19  17:05:00    1   \n",
       "1111        1111          1111  28926  1992   3  1992-03-18  08:20:00    0   \n",
       "1112        1112          1112  28962  1974   6  1974-06-07  11:30:00    1   \n",
       "1113        1113          1113  28984  2013   5  2013-05-31  05:05:00    1   \n",
       "\n",
       "         SLAT     SLON     ELAT     ELON    LEN  WID  Fatalities  Injuries  \\\n",
       "0     36.2971 -82.3174  36.2934 -82.3021   0.89   50           0         0   \n",
       "1     36.3000 -82.4341  36.3000 -82.4341   3.00  150           0         0   \n",
       "2     36.3037 -82.3923  36.3099 -82.3846   0.61  100           0         0   \n",
       "3     36.0424 -82.5568  36.0477 -82.5393   1.04   50           0         0   \n",
       "4     36.2255 -83.0570  36.2263 -83.0486   0.50   70           0         0   \n",
       "...       ...      ...      ...      ...    ...  ...         ...       ...   \n",
       "1109  35.0000 -90.0000   0.0000   0.0000   0.10   10           0         0   \n",
       "1110  35.1300 -90.0200  35.2800 -89.9300  10.00   50           0         0   \n",
       "1111  35.2200 -89.7700   0.0000   0.0000   1.50   50           0         0   \n",
       "1112  35.5700 -89.6500   0.0000   0.0000   0.30  100           1         1   \n",
       "1113  35.6159 -89.7031  35.6142 -89.6884   0.83  250           0         0   \n",
       "\n",
       "      Property Loss    starting county      ending county  \n",
       "0               4.0      Carter County      Carter County  \n",
       "1               5.0  Washington County  Washington County  \n",
       "2               4.0  Washington County  Washington County  \n",
       "3               4.0      Unicoi County      Unicoi County  \n",
       "4               3.0      Greene County      Greene County  \n",
       "...             ...                ...                ...  \n",
       "1109            4.0      Shelby County                NaN  \n",
       "1110            6.0      Shelby County      Shelby County  \n",
       "1111            4.0      Shelby County                NaN  \n",
       "1112            4.0      Tipton County                NaN  \n",
       "1113            5.0      Tipton County      Tipton County  \n",
       "\n",
       "[1114 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv('/Users/savannahposner/Desktop/bigProject/Tennessee_Tornadoes/Updated_Cleaned.csv')\n",
    "df_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3d1a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'FID', 'YR', 'MO', 'DATE', 'TIME', 'MAG',\n",
       "       'SLAT', 'SLON', 'ELAT', 'ELON', 'LEN', 'WID', 'Fatalities', 'Injuries',\n",
       "       'Property Loss', 'starting county', 'ending county'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df_1.dropna()\n",
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707a1e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1.loc[df_1['Fatalities'] > 20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ec5c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YR', 'MO', 'DATE', 'MAG', 'Fatalities', 'Property Loss'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df_1.drop([ 'YR','Unnamed: 0','Unnamed: 0.1','DATE','TIME',\n",
    "#                'SLAT','SLON','ELAT','ELON','LEN','ending county'], axis=1)\n",
    "\n",
    "df = df_1.drop(['Unnamed: 0','Unnamed: 0.1','TIME',\"starting county\",\n",
    "              'SLAT','SLON','Injuries','ELAT','WID','ELON','LEN','ending county','FID'], axis=1)\n",
    "# df = df_1.drop(df.loc[df['Fatalities'] > 90], axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00d4824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DATE</th>\n",
       "      <th>MAG</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Property Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>2009-06-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-07-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1991</td>\n",
       "      <td>11</td>\n",
       "      <td>1991-11-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        YR  MO        DATE  MAG  Fatalities  Property Loss\n",
       "0     2011   4  2011-04-09    0           0            4.0\n",
       "1     2011   4  2011-04-09    1           0            5.0\n",
       "2     2011   4  2011-04-09    1           0            4.0\n",
       "3     2011   4  2011-04-09    0           0            4.0\n",
       "4     2011   4  2011-04-27    0           0            3.0\n",
       "...    ...  ..         ...  ...         ...            ...\n",
       "1103  2009   6  2009-06-12    1           0            4.0\n",
       "1104  2009   7  2009-07-30    1           0            5.0\n",
       "1107  2010   5  2010-05-01    1           0            4.0\n",
       "1110  1991  11  1991-11-19    1           0            6.0\n",
       "1113  2013   5  2013-05-31    1           0            5.0\n",
       "\n",
       "[686 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "# Date, Starting county, property loss \n",
    "\n",
    "# Magnitude, DATE, MO, STARTING COUNTY,YR, WID,\n",
    "#STARTING COUNTy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d138115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "\n",
    "target = 'MAG'\n",
    "X = pd.get_dummies(df.drop(columns=target))\n",
    "\n",
    "\n",
    "# Create our target\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3203ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1f103",
   "metadata": {},
   "source": [
    "### Run through the Models Provided in the Module 17 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76c76ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive random oversampling\n",
      "\n",
      "The accuracy score: \n",
      "0.4663570162107396\n",
      "\n",
      "The accuracy score: \n",
      "0.4663570162107396\n",
      "\n",
      "SMOTE\n",
      "\n",
      "An Error as occured\n",
      "Random Under Sampler\n",
      "\n",
      "The accuracy score: \n",
      "0.327040273556231\n",
      "\n",
      "SMOTEENN\n",
      "\n",
      "An Error as occured\n",
      "Balanced Random Forest Classifier \n",
      "\n",
      "The accuracy score: \n",
      "0.4060904255319149\n",
      "\n",
      "Easy Ensemble Classifier \n",
      "\n",
      "The accuracy score: \n",
      "0.22999999999999998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x =\"An Error as occured\"\n",
    "try:\n",
    "\n",
    "    print(f\"naive random oversampling\\n\")\n",
    "# Resample the training data with the RandomOversampler\n",
    "\n",
    "    ros = RandomOverSampler(random_state=1)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "    \n",
    "except:\n",
    "      print(x)\n",
    "\n",
    "\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "try:\n",
    "\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "# Print the imbalanced classification report\n",
    "   \n",
    "\n",
    "# Resample the training data with SMOTE\n",
    "    print(f\"SMOTE\\n\")\n",
    "    X_resampled, y_resampled = SMOTE(random_state=1,\n",
    "    sampling_strategy='auto').fit_resample(\n",
    "       X_train, y_train)\n",
    "    Counter(y_resampled)\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    \n",
    "except:\n",
    "      print(x)\n",
    "# Resample the data using the ClusterCentroids resampler\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "# Resample the training data with SMOTE\n",
    "\n",
    "try: \n",
    "    print(f\"Random Under Sampler\\n\")\n",
    "    ros = RandomUnderSampler(random_state=1)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    Counter(y_resampled)\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    \n",
    "except:\n",
    "      print(x)\n",
    "# Resample the training data with SMOTEENN\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "# YOUR CODE HERE\n",
    "try:\n",
    "    print(f\"SMOTEENN\\n\")\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "    Counter(y_resampled)\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    \n",
    "except:  \n",
    "      print(x)\n",
    "\n",
    "\n",
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "try:\n",
    "    print(f\"Balanced Random Forest Classifier \\n\")\n",
    "    model = BalancedRandomForestClassifier(n_estimators =100, random_state=1)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    # Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "\n",
    "except:\n",
    "    print(x)\n",
    "\n",
    "# Train the EasyEnsembleClassifier\n",
    "try:\n",
    "    print(f\"Easy Ensemble Classifier \\n\")\n",
    "\n",
    "# Train the EasyEnsembleClassifier\n",
    "    from imblearn.ensemble import EasyEnsembleClassifier \n",
    "    model = EasyEnsembleClassifier(n_estimators =100, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "except:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39090f35",
   "metadata": {},
   "source": [
    "### Additional Machine Learning Models that we can try "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af4066",
   "metadata": {},
   "source": [
    "#### SGDClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24d694",
   "metadata": {},
   "source": [
    "link to reference: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbeab8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.3792439209726444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sklearn.linear_model.SGDClassifier\n",
    "\n",
    "\n",
    "# This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: \n",
    "#     the gradient of the loss is estimated each sample at a time and the model is updated \n",
    "#     along the way with a decreasing strength schedule (aka learning rate).\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "# X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "# Counter(y_resampled)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04633fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0adc0385",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da010d14",
   "metadata": {},
   "source": [
    "link to reference: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b701fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.3444617527862208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When performing classification you often want to predict not only the class label, \n",
    "# but also the associated probability. \n",
    "# This probability gives you some kind of confidence on the prediction\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)  # GaussianNB itself does not support sample-weights\n",
    "\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abcbe1e",
   "metadata": {},
   "source": [
    " RandomOverSampler: Using differnt solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c2db5",
   "metadata": {},
   "source": [
    "link to reference https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "412e4728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.5269845491388044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c995dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.5269845491388044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45c88383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.34681420972644383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = LogisticRegression(solver='sag', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ccdda0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.565850430597771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = LogisticRegression(solver='newton-cg', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4d88041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.34348214285714285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = LogisticRegression(solver='saga', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c56af8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.5897771023302938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = make_pipeline(StandardScaler(),LogisticRegression(solver='newton-cg'))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# model = LogisticRegression(solver='newton-cg', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f2f09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a6f71b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.5897771023302938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    MinMaxScaler(),\n",
    "    PolynomialCountSketch(degree=2, n_components=300),\n",
    "    LogisticRegression(),\n",
    ")\n",
    "\n",
    "pipe.fit(X_resampled, y_resampled).score(X_resampled, y_resampled)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90c3a623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48255813953488375"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_3 = df.drop(['Unnamed: 0','Unnamed: 0.1','TIME',\"WID\",\"starting county\",\n",
    "#               'SLAT','SLON','ELAT','ELON','LEN','ending county','FID'], axis=1)\n",
    "# df.columns\n",
    "\n",
    "\n",
    "# target = 'Property Loss'\n",
    "# X = pd.get_dummies(df_3.drop([target],axis = 1))\n",
    "\n",
    "\n",
    "# # Create our target\n",
    "# y = df[target]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1)\n",
    "\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    PolynomialCountSketch(degree=2, n_components=650),\n",
    "    LogisticRegression(max_iter=1000),\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f4ca8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0019896287707794613\n",
      "0.5247733342114147\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1)\n",
    "\n",
    "glm = PoissonRegressor()\n",
    "gbdt = HistGradientBoostingRegressor(loss=\"poisson\", learning_rate=0.01)\n",
    "glm.fit(X_train, y_train)\n",
    "gbdt.fit(X_train, y_train)\n",
    "print(glm.score(X_test, y_test))\n",
    "print(gbdt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e38ebaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18400742501804068\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "sample_weight = rng.rand(686)\n",
    "X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(\n",
    "    X, y, sample_weight, random_state=1)\n",
    "reg = Lasso()\n",
    "reg.fit(X_train, y_train, sample_weight=sw_train)\n",
    "print(reg.score(X_test, y_test, sw_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048043c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be46d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753fb696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a2823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9cc1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
