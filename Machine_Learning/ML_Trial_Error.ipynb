{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee664430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0a1c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a4ae17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>FID</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>MAG</th>\n",
       "      <th>SLAT</th>\n",
       "      <th>SLON</th>\n",
       "      <th>ELAT</th>\n",
       "      <th>ELON</th>\n",
       "      <th>LEN</th>\n",
       "      <th>WID</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Injuries</th>\n",
       "      <th>Property Loss</th>\n",
       "      <th>starting county</th>\n",
       "      <th>ending county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23025</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>14:35:00</td>\n",
       "      <td>0</td>\n",
       "      <td>36.2971</td>\n",
       "      <td>-82.3174</td>\n",
       "      <td>36.2934</td>\n",
       "      <td>-82.3021</td>\n",
       "      <td>0.89</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Carter County</td>\n",
       "      <td>Carter County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23027</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>36.3000</td>\n",
       "      <td>-82.4341</td>\n",
       "      <td>36.3000</td>\n",
       "      <td>-82.4341</td>\n",
       "      <td>3.00</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Washington County</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23028</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>16:08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>36.3037</td>\n",
       "      <td>-82.3923</td>\n",
       "      <td>36.3099</td>\n",
       "      <td>-82.3846</td>\n",
       "      <td>0.61</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Washington County</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23029</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>16:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0424</td>\n",
       "      <td>-82.5568</td>\n",
       "      <td>36.0477</td>\n",
       "      <td>-82.5393</td>\n",
       "      <td>1.04</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Unicoi County</td>\n",
       "      <td>Unicoi County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>23044</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>19:07:00</td>\n",
       "      <td>0</td>\n",
       "      <td>36.2255</td>\n",
       "      <td>-83.0570</td>\n",
       "      <td>36.2263</td>\n",
       "      <td>-83.0486</td>\n",
       "      <td>0.50</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Greene County</td>\n",
       "      <td>Greene County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1109</td>\n",
       "      <td>1109</td>\n",
       "      <td>28915</td>\n",
       "      <td>1967</td>\n",
       "      <td>7</td>\n",
       "      <td>1967-07-05</td>\n",
       "      <td>14:25:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>-90.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Shelby County</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1110</td>\n",
       "      <td>1110</td>\n",
       "      <td>28916</td>\n",
       "      <td>1991</td>\n",
       "      <td>11</td>\n",
       "      <td>1991-11-19</td>\n",
       "      <td>17:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.1300</td>\n",
       "      <td>-90.0200</td>\n",
       "      <td>35.2800</td>\n",
       "      <td>-89.9300</td>\n",
       "      <td>10.00</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Shelby County</td>\n",
       "      <td>Shelby County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1111</td>\n",
       "      <td>1111</td>\n",
       "      <td>28926</td>\n",
       "      <td>1992</td>\n",
       "      <td>3</td>\n",
       "      <td>1992-03-18</td>\n",
       "      <td>08:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>35.2200</td>\n",
       "      <td>-89.7700</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Shelby County</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1112</td>\n",
       "      <td>1112</td>\n",
       "      <td>28962</td>\n",
       "      <td>1974</td>\n",
       "      <td>6</td>\n",
       "      <td>1974-06-07</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.5700</td>\n",
       "      <td>-89.6500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Tipton County</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>28984</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>05:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.6159</td>\n",
       "      <td>-89.7031</td>\n",
       "      <td>35.6142</td>\n",
       "      <td>-89.6884</td>\n",
       "      <td>0.83</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Tipton County</td>\n",
       "      <td>Tipton County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1    FID    YR  MO        DATE      TIME  MAG  \\\n",
       "0              0             0  23025  2011   4  2011-04-09  14:35:00    0   \n",
       "1              1             1  23027  2011   4  2011-04-09  16:00:00    1   \n",
       "2              2             2  23028  2011   4  2011-04-09  16:08:00    1   \n",
       "3              3             3  23029  2011   4  2011-04-09  16:15:00    0   \n",
       "4              4             4  23044  2011   4  2011-04-27  19:07:00    0   \n",
       "...          ...           ...    ...   ...  ..         ...       ...  ...   \n",
       "1109        1109          1109  28915  1967   7  1967-07-05  14:25:00    1   \n",
       "1110        1110          1110  28916  1991  11  1991-11-19  17:05:00    1   \n",
       "1111        1111          1111  28926  1992   3  1992-03-18  08:20:00    0   \n",
       "1112        1112          1112  28962  1974   6  1974-06-07  11:30:00    1   \n",
       "1113        1113          1113  28984  2013   5  2013-05-31  05:05:00    1   \n",
       "\n",
       "         SLAT     SLON     ELAT     ELON    LEN  WID  Fatalities  Injuries  \\\n",
       "0     36.2971 -82.3174  36.2934 -82.3021   0.89   50           0         0   \n",
       "1     36.3000 -82.4341  36.3000 -82.4341   3.00  150           0         0   \n",
       "2     36.3037 -82.3923  36.3099 -82.3846   0.61  100           0         0   \n",
       "3     36.0424 -82.5568  36.0477 -82.5393   1.04   50           0         0   \n",
       "4     36.2255 -83.0570  36.2263 -83.0486   0.50   70           0         0   \n",
       "...       ...      ...      ...      ...    ...  ...         ...       ...   \n",
       "1109  35.0000 -90.0000   0.0000   0.0000   0.10   10           0         0   \n",
       "1110  35.1300 -90.0200  35.2800 -89.9300  10.00   50           0         0   \n",
       "1111  35.2200 -89.7700   0.0000   0.0000   1.50   50           0         0   \n",
       "1112  35.5700 -89.6500   0.0000   0.0000   0.30  100           1         1   \n",
       "1113  35.6159 -89.7031  35.6142 -89.6884   0.83  250           0         0   \n",
       "\n",
       "      Property Loss    starting county      ending county  \n",
       "0               4.0      Carter County      Carter County  \n",
       "1               5.0  Washington County  Washington County  \n",
       "2               4.0  Washington County  Washington County  \n",
       "3               4.0      Unicoi County      Unicoi County  \n",
       "4               3.0      Greene County      Greene County  \n",
       "...             ...                ...                ...  \n",
       "1109            4.0      Shelby County                NaN  \n",
       "1110            6.0      Shelby County      Shelby County  \n",
       "1111            4.0      Shelby County                NaN  \n",
       "1112            4.0      Tipton County                NaN  \n",
       "1113            5.0      Tipton County      Tipton County  \n",
       "\n",
       "[1114 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv('/Users/savannahposner/Desktop/bigProject/Tennessee_Tornadoes/Updated_Cleaned.csv')\n",
    "df_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3d1a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'FID', 'YR', 'MO', 'DATE', 'TIME', 'MAG',\n",
       "       'SLAT', 'SLON', 'ELAT', 'ELON', 'LEN', 'WID', 'Fatalities', 'Injuries',\n",
       "       'Property Loss', 'starting county', 'ending county'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df_1.dropna()\n",
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ec5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_1.drop([ 'YR','Unnamed: 0','Unnamed: 0.1','DATE','TIME',\n",
    "#                'SLAT','SLON','ELAT','ELON','LEN','ending county'], axis=1)\n",
    "\n",
    "df = df_1.drop([ 'MO','Unnamed: 0','Unnamed: 0.1','YR','TIME',\n",
    "              'SLAT','SLON','ELAT','ELON','LEN','ending county','starting county','Injuries','Fatalities','FID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6715fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>MAG</th>\n",
       "      <th>WID</th>\n",
       "      <th>Property Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>2009-06-12</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>2009-07-30</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>2010-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1991-11-19</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE  MAG  WID  Property Loss\n",
       "0     2011-04-09    0   50            4.0\n",
       "1     2011-04-09    1  150            5.0\n",
       "2     2011-04-09    1  100            4.0\n",
       "3     2011-04-09    0   50            4.0\n",
       "4     2011-04-27    0   70            3.0\n",
       "...          ...  ...  ...            ...\n",
       "1103  2009-06-12    1   30            4.0\n",
       "1104  2009-07-30    1  250            5.0\n",
       "1107  2010-05-01    1  100            4.0\n",
       "1110  1991-11-19    1   50            6.0\n",
       "1113  2013-05-31    1  250            5.0\n",
       "\n",
       "[686 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "# Date, Starting county, property loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d138115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "\n",
    "target = 'MAG'\n",
    "X = pd.get_dummies(df.drop(columns=target))\n",
    "\n",
    "\n",
    "# Create our target\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3203ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1f103",
   "metadata": {},
   "source": [
    "### Run through the Models Provided in the Module 17 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76c76ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive random oversampling\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31  0  3  1  0  0]\n",
      " [32  0 10 21  1  0]\n",
      " [15  0  2 25  4  1]\n",
      " [ 4  0  0  9  5  2]\n",
      " [ 1  0  0  2  3  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "\n",
      "The accuracy score: \n",
      "0.37565349544072946\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.37      0.89      0.62      0.53      0.74      0.56        35\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00        64\n",
      "          2       0.13      0.04      0.90      0.06      0.20      0.03        47\n",
      "          3       0.16      0.45      0.68      0.23      0.55      0.30        20\n",
      "          4       0.23      0.50      0.94      0.32      0.69      0.45         6\n",
      "          5       0.00      0.00      0.98      0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.14      0.26      0.85      0.16      0.29      0.17       172\n",
      "\n",
      "SMOTE\n",
      "\n",
      "An Error as occured\n",
      "Random Under Sampler\n",
      "\n",
      "The accuracy score: \n",
      "0.19972771023302938\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11 20  0  3  1  0]\n",
      " [21 14  6 16  7  0]\n",
      " [10  6  7 14  7  3]\n",
      " [ 3  1  3  3  4  6]\n",
      " [ 1  0  1  1  1  2]\n",
      " [ 0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.24      0.31      0.74      0.27      0.48      0.22        35\n",
      "          1       0.34      0.22      0.75      0.27      0.41      0.16        64\n",
      "          2       0.41      0.15      0.92      0.22      0.37      0.13        47\n",
      "          3       0.08      0.15      0.78      0.11      0.34      0.11        20\n",
      "          4       0.05      0.17      0.89      0.08      0.38      0.14         6\n",
      "          5       0.00      0.00      0.94      0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.30      0.21      0.80      0.23      0.40      0.16       172\n",
      "\n",
      "SMOTEENN\n",
      "\n",
      "An Error as occured\n",
      "Balanced Random Forest Classifier \n",
      "\n",
      "The accuracy score: \n",
      "0.3446713525835866\n",
      "\n",
      "Confusion Matrix:\n",
      "[[34  1  0  0  0  0]\n",
      " [44  7  3 10  0  0]\n",
      " [22  4  2 17  0  2]\n",
      " [ 4  1  1 12  1  1]\n",
      " [ 1  1  0  4  0  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.32      0.97      0.48      0.49      0.68      0.49        35\n",
      "          1       0.50      0.11      0.94      0.18      0.32      0.09        64\n",
      "          2       0.33      0.04      0.97      0.08      0.20      0.04        47\n",
      "          3       0.28      0.60      0.80      0.38      0.69      0.47        20\n",
      "          4       0.00      0.00      0.99      0.00      0.00      0.00         6\n",
      "          5       0.00      0.00      0.98      0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.38      0.32      0.84      0.23      0.39      0.20       172\n",
      "\n",
      "Easy Ensemble Classifier \n",
      "\n",
      "The accuracy score: \n",
      "0.29047619047619044\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0 17  8  0]\n",
      " [ 1  0  0 36 27  0]\n",
      " [ 0  0  0 23 24  0]\n",
      " [ 0  0  0 10  9  1]\n",
      " [ 0  0  0  2  4  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.91      0.29      0.99      0.43      0.53      0.26        35\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00        64\n",
      "          2       0.00      0.00      1.00      0.00      0.00      0.00        47\n",
      "          3       0.11      0.50      0.49      0.19      0.49      0.24        20\n",
      "          4       0.06      0.67      0.59      0.10      0.63      0.40         6\n",
      "          5       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.20      0.14      0.92      0.11      0.19      0.10       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x =\"An Error as occured\"\n",
    "try:\n",
    "\n",
    "    print(f\"naive random oversampling\\n\")\n",
    "# Resample the training data with the RandomOversampler\n",
    "\n",
    "    ros = RandomOverSampler(random_state=1)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "except:\n",
    "      print(x)\n",
    "\n",
    "\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "try:\n",
    "\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "\n",
    "# Resample the training data with SMOTE\n",
    "    print(f\"SMOTE\\n\")\n",
    "    X_resampled, y_resampled = SMOTE(random_state=1,\n",
    "    sampling_strategy='auto').fit_resample(\n",
    "       X_train, y_train)\n",
    "    Counter(y_resampled)\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "\n",
    "except:\n",
    "      print(x)\n",
    "# Resample the data using the ClusterCentroids resampler\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "# Resample the training data with SMOTE\n",
    "\n",
    "try: \n",
    "    print(f\"Random Under Sampler\\n\")\n",
    "    ros = RandomUnderSampler(random_state=1)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    Counter(y_resampled)\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "except:\n",
    "      print(x)\n",
    "# Resample the training data with SMOTEENN\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "# YOUR CODE HERE\n",
    "try:\n",
    "    print(f\"SMOTEENN\\n\")\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "    Counter(y_resampled)\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "except:  \n",
    "      print(x)\n",
    "\n",
    "\n",
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "try:\n",
    "    print(f\"Balanced Random Forest Classifier \\n\")\n",
    "    model = BalancedRandomForestClassifier(n_estimators =100, random_state=1)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    # Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "except:\n",
    "    print(x)\n",
    "\n",
    "# Train the EasyEnsembleClassifier\n",
    "try:\n",
    "    print(f\"Easy Ensemble Classifier \\n\")\n",
    "\n",
    "# Train the EasyEnsembleClassifier\n",
    "    from imblearn.ensemble import EasyEnsembleClassifier \n",
    "    model = EasyEnsembleClassifier(n_estimators =100, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "    \n",
    "except:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39090f35",
   "metadata": {},
   "source": [
    "### Additional Machine Learning Models that we can try "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af4066",
   "metadata": {},
   "source": [
    "#### SGDClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24d694",
   "metadata": {},
   "source": [
    "link to reference: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbeab8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.48251963019250266\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17 13  4  1  0  0]\n",
      " [ 9 45  9  1  0  0]\n",
      " [ 0 26 16  4  1  0]\n",
      " [ 0  5  3 11  0  1]\n",
      " [ 0  1  1  2  2  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.65      0.49      0.93      0.56      0.67      0.43        35\n",
      "          1       0.50      0.70      0.58      0.58      0.64      0.42        64\n",
      "          2       0.48      0.34      0.86      0.40      0.54      0.28        47\n",
      "          3       0.58      0.55      0.95      0.56      0.72      0.50        20\n",
      "          4       0.67      0.33      0.99      0.44      0.58      0.31         6\n",
      "          5       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.54      0.53      0.79      0.52      0.63      0.39       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sklearn.linear_model.SGDClassifier\n",
    "\n",
    "\n",
    "# This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: \n",
    "#     the gradient of the loss is estimated each sample at a time and the model is updated \n",
    "#     along the way with a decreasing strength schedule (aka learning rate).\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "# X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "# Counter(y_resampled)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc0385",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da010d14",
   "metadata": {},
   "source": [
    "link to reference: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b701fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.3444617527862208\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11  0  3  5 16]\n",
      " [19 10  1  4 30]\n",
      " [ 8  3  4  7 25]\n",
      " [ 2  1  0 10  7]\n",
      " [ 1  0  0  1  4]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.27      0.31      0.78      0.29      0.50      0.23        35\n",
      "          1       0.71      0.16      0.96      0.26      0.39      0.14        64\n",
      "          2       0.50      0.09      0.97      0.15      0.29      0.08        47\n",
      "          3       0.37      0.50      0.89      0.43      0.67      0.43        20\n",
      "          4       0.05      0.67      0.53      0.09      0.59      0.36         6\n",
      "\n",
      "avg / total       0.50      0.23      0.90      0.25      0.42      0.18       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When performing classification you often want to predict not only the class label, \n",
    "# but also the associated probability. \n",
    "# This probability gives you some kind of confidence on the prediction\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)  # GaussianNB itself does not support sample-weights\n",
    "\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abcbe1e",
   "metadata": {},
   "source": [
    " RandomOverSampler: Using differnt solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c2db5",
   "metadata": {},
   "source": [
    "link to reference https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "412e4728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.5385948581560285\n",
      "\n",
      "Confusion Matrix:\n",
      "[[21 10  3  1  0  0]\n",
      " [14 35 13  1  1  0]\n",
      " [ 6 16 10  3 11  1]\n",
      " [ 0  2  2 10  5  1]\n",
      " [ 0  0  0  1  5  0]\n",
      " [ 0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.51      0.60      0.85      0.55      0.72      0.50        35\n",
      "          1       0.56      0.55      0.74      0.55      0.64      0.40        64\n",
      "          2       0.36      0.21      0.86      0.27      0.43      0.17        47\n",
      "          3       0.62      0.50      0.96      0.56      0.69      0.46        20\n",
      "          4       0.23      0.83      0.90      0.36      0.86      0.74         6\n",
      "          5       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.49      0.47      0.83      0.47      0.61      0.38       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995dcac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c88383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccdda0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0daf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
