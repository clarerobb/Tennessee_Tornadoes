{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ee664430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4f0a1c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c7a4ae17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>FID</th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>MAG</th>\n",
       "      <th>SLAT</th>\n",
       "      <th>SLON</th>\n",
       "      <th>ELAT</th>\n",
       "      <th>ELON</th>\n",
       "      <th>LEN</th>\n",
       "      <th>WID</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Injuries</th>\n",
       "      <th>Property Loss</th>\n",
       "      <th>starting county</th>\n",
       "      <th>ending county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23025</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>14:35:00</td>\n",
       "      <td>0</td>\n",
       "      <td>36.2971</td>\n",
       "      <td>-82.3174</td>\n",
       "      <td>36.2934</td>\n",
       "      <td>-82.3021</td>\n",
       "      <td>0.89</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Carter County</td>\n",
       "      <td>Carter County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23027</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>36.3000</td>\n",
       "      <td>-82.4341</td>\n",
       "      <td>36.3000</td>\n",
       "      <td>-82.4341</td>\n",
       "      <td>3.00</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Washington County</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23028</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>16:08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>36.3037</td>\n",
       "      <td>-82.3923</td>\n",
       "      <td>36.3099</td>\n",
       "      <td>-82.3846</td>\n",
       "      <td>0.61</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Washington County</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23029</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>16:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0424</td>\n",
       "      <td>-82.5568</td>\n",
       "      <td>36.0477</td>\n",
       "      <td>-82.5393</td>\n",
       "      <td>1.04</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Unicoi County</td>\n",
       "      <td>Unicoi County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>23044</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>19:07:00</td>\n",
       "      <td>0</td>\n",
       "      <td>36.2255</td>\n",
       "      <td>-83.0570</td>\n",
       "      <td>36.2263</td>\n",
       "      <td>-83.0486</td>\n",
       "      <td>0.50</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Greene County</td>\n",
       "      <td>Greene County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1109</td>\n",
       "      <td>1109</td>\n",
       "      <td>28915</td>\n",
       "      <td>1967</td>\n",
       "      <td>7</td>\n",
       "      <td>1967-07-05</td>\n",
       "      <td>14:25:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>-90.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Shelby County</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1110</td>\n",
       "      <td>1110</td>\n",
       "      <td>28916</td>\n",
       "      <td>1991</td>\n",
       "      <td>11</td>\n",
       "      <td>1991-11-19</td>\n",
       "      <td>17:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.1300</td>\n",
       "      <td>-90.0200</td>\n",
       "      <td>35.2800</td>\n",
       "      <td>-89.9300</td>\n",
       "      <td>10.00</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Shelby County</td>\n",
       "      <td>Shelby County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1111</td>\n",
       "      <td>1111</td>\n",
       "      <td>28926</td>\n",
       "      <td>1992</td>\n",
       "      <td>3</td>\n",
       "      <td>1992-03-18</td>\n",
       "      <td>08:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>35.2200</td>\n",
       "      <td>-89.7700</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Shelby County</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>1112</td>\n",
       "      <td>1112</td>\n",
       "      <td>28962</td>\n",
       "      <td>1974</td>\n",
       "      <td>6</td>\n",
       "      <td>1974-06-07</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.5700</td>\n",
       "      <td>-89.6500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Tipton County</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1113</td>\n",
       "      <td>1113</td>\n",
       "      <td>28984</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>05:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.6159</td>\n",
       "      <td>-89.7031</td>\n",
       "      <td>35.6142</td>\n",
       "      <td>-89.6884</td>\n",
       "      <td>0.83</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Tipton County</td>\n",
       "      <td>Tipton County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1    FID    YR  MO        DATE      TIME  MAG  \\\n",
       "0              0             0  23025  2011   4  2011-04-09  14:35:00    0   \n",
       "1              1             1  23027  2011   4  2011-04-09  16:00:00    1   \n",
       "2              2             2  23028  2011   4  2011-04-09  16:08:00    1   \n",
       "3              3             3  23029  2011   4  2011-04-09  16:15:00    0   \n",
       "4              4             4  23044  2011   4  2011-04-27  19:07:00    0   \n",
       "...          ...           ...    ...   ...  ..         ...       ...  ...   \n",
       "1109        1109          1109  28915  1967   7  1967-07-05  14:25:00    1   \n",
       "1110        1110          1110  28916  1991  11  1991-11-19  17:05:00    1   \n",
       "1111        1111          1111  28926  1992   3  1992-03-18  08:20:00    0   \n",
       "1112        1112          1112  28962  1974   6  1974-06-07  11:30:00    1   \n",
       "1113        1113          1113  28984  2013   5  2013-05-31  05:05:00    1   \n",
       "\n",
       "         SLAT     SLON     ELAT     ELON    LEN  WID  Fatalities  Injuries  \\\n",
       "0     36.2971 -82.3174  36.2934 -82.3021   0.89   50           0         0   \n",
       "1     36.3000 -82.4341  36.3000 -82.4341   3.00  150           0         0   \n",
       "2     36.3037 -82.3923  36.3099 -82.3846   0.61  100           0         0   \n",
       "3     36.0424 -82.5568  36.0477 -82.5393   1.04   50           0         0   \n",
       "4     36.2255 -83.0570  36.2263 -83.0486   0.50   70           0         0   \n",
       "...       ...      ...      ...      ...    ...  ...         ...       ...   \n",
       "1109  35.0000 -90.0000   0.0000   0.0000   0.10   10           0         0   \n",
       "1110  35.1300 -90.0200  35.2800 -89.9300  10.00   50           0         0   \n",
       "1111  35.2200 -89.7700   0.0000   0.0000   1.50   50           0         0   \n",
       "1112  35.5700 -89.6500   0.0000   0.0000   0.30  100           1         1   \n",
       "1113  35.6159 -89.7031  35.6142 -89.6884   0.83  250           0         0   \n",
       "\n",
       "      Property Loss    starting county      ending county  \n",
       "0               4.0      Carter County      Carter County  \n",
       "1               5.0  Washington County  Washington County  \n",
       "2               4.0  Washington County  Washington County  \n",
       "3               4.0      Unicoi County      Unicoi County  \n",
       "4               3.0      Greene County      Greene County  \n",
       "...             ...                ...                ...  \n",
       "1109            4.0      Shelby County                NaN  \n",
       "1110            6.0      Shelby County      Shelby County  \n",
       "1111            4.0      Shelby County                NaN  \n",
       "1112            4.0      Tipton County                NaN  \n",
       "1113            5.0      Tipton County      Tipton County  \n",
       "\n",
       "[1114 rows x 19 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv('/Users/savannahposner/Desktop/bigProject/Tennessee_Tornadoes/Updated_Cleaned.csv')\n",
    "df_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "86eceacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# East_TN = [\"Anderson County\",\"Blount County\",\"Campbell County\",\"Carter County\",\"Claiborne County\",\"Cocke County\",\"Grainger County\",\"Hamblen County\",\"Hancock County\"\"Hawkins County\",\"Jefferson County\",\"Johnson County\",\"Knox County\",\"Loudon County\"\"McMinn County\",\"Monroe County\"\"Morgan County\",\"Roane County\"\"Scott County\",\"Sevier County\",\"Sullivan County\",\"Unicoi County\",\"Union County\",\"Washington County\"]\n",
    "\n",
    "\n",
    "# West_TN =[\"Benton County\",\"Carroll County\",\"Chester County\",\"Crockett County\",\"Decatur County\",\"Dyer County\",\"Fayette County\",\"Gibson County\",\"Hardeman County\",\"Hardin County\",\"Haywood County\",\"Henderson County\",\"Henry County\",\"Lake County\",\"Lauderdale County\",\"Madison County\",\"McNairy County\",\"Obion County\",\"Shelby County\",\"Tipton County\",\"Weakley County\"]\n",
    "\n",
    "\n",
    "# Middle_TN = [\"Bedford County\",\"Cannon County\",\"Cheatham County\",\"Clay County\",\"Davidson County\",\"DeKalb County\",\"Dickson County\",\"Fentress County\",\"Franklin County\",\"Giles County\",\"Grundy County\",\"Hickman County\",\"Houston County\",\"Humphreys County\",\"Jackson County\",\"Lawrence County\",\"Lewis County\",\"Lincoln County\",\"Macon County\",\"Marshall County\",\"Maury County\",\"Montgomery County\"\"Moore County\",\"Overton County\",\"Perry County\",\"Pickett County\",\"Putnam County\",\"Robertson County\",\"Rutherford County\",\"Sequatchie County\",\"Smith County\",\"Stewart County\",\"Sumner County\",\"Trousdale County\",\"Van Buren County\",\"Warren County\",\"Wayne County\",\"White County\",\"Williamson County\",\"Wilson County\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for x in range(0,len(df_1[\"starting county\"])): \n",
    "#     #for e in range(0,len(East_TN)): \n",
    "#         if df_1['starting county'][x] in East_TN:\n",
    "#             df_1['Tennessee Area'] = 'E'\n",
    "            \n",
    "#  #   for e in range(0,len(Middle_TN)): \n",
    "#         if  df_1['starting county'][x] in Middle_TN:\n",
    "#             df_1['Tennessee Area'] = 'M'\n",
    "            \n",
    "            \n",
    "#   # for e in range(0,len(West_TN)): \n",
    "#         if  df_1['starting county'][x] in West_TN:\n",
    "#             df_1['Tennessee Area'] = 'W'\n",
    "#         x = x+1\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "# df_1[\"Tennessee Area\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2f3d1a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'FID', 'YR', 'MO', 'DATE', 'TIME', 'MAG',\n",
       "       'SLAT', 'SLON', 'ELAT', 'ELON', 'LEN', 'WID', 'Fatalities', 'Injuries',\n",
       "       'Property Loss', 'starting county', 'ending county'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df_1.dropna()\n",
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "01ec5c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YR', 'MO', 'DATE', 'MAG', 'WID', 'Fatalities', 'Property Loss',\n",
       "       'starting county'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df_1.drop([ 'YR','Unnamed: 0','Unnamed: 0.1','DATE','TIME',\n",
    "#                'SLAT','SLON','ELAT','ELON','LEN','ending county'], axis=1)\n",
    "\n",
    "df = df_1.drop(['Unnamed: 0','Unnamed: 0.1','TIME',\n",
    "              'SLAT','SLON','ELAT','ELON','LEN','ending county','Injuries','FID'], axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1a682aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YR</th>\n",
       "      <th>MO</th>\n",
       "      <th>DATE</th>\n",
       "      <th>MAG</th>\n",
       "      <th>WID</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Property Loss</th>\n",
       "      <th>starting county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Carter County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Unicoi County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Greene County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>2009-06-12</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Shelby County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-07-30</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Shelby County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Shelby County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1991</td>\n",
       "      <td>11</td>\n",
       "      <td>1991-11-19</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Shelby County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Tipton County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        YR  MO        DATE  MAG  WID  Fatalities  Property Loss  \\\n",
       "0     2011   4  2011-04-09    0   50           0            4.0   \n",
       "1     2011   4  2011-04-09    1  150           0            5.0   \n",
       "2     2011   4  2011-04-09    1  100           0            4.0   \n",
       "3     2011   4  2011-04-09    0   50           0            4.0   \n",
       "4     2011   4  2011-04-27    0   70           0            3.0   \n",
       "...    ...  ..         ...  ...  ...         ...            ...   \n",
       "1103  2009   6  2009-06-12    1   30           0            4.0   \n",
       "1104  2009   7  2009-07-30    1  250           0            5.0   \n",
       "1107  2010   5  2010-05-01    1  100           0            4.0   \n",
       "1110  1991  11  1991-11-19    1   50           0            6.0   \n",
       "1113  2013   5  2013-05-31    1  250           0            5.0   \n",
       "\n",
       "        starting county  \n",
       "0         Carter County  \n",
       "1     Washington County  \n",
       "2     Washington County  \n",
       "3         Unicoi County  \n",
       "4         Greene County  \n",
       "...                 ...  \n",
       "1103      Shelby County  \n",
       "1104      Shelby County  \n",
       "1107      Shelby County  \n",
       "1110      Shelby County  \n",
       "1113      Tipton County  \n",
       "\n",
       "[686 rows x 8 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "# Date, Starting county, property loss \n",
    "\n",
    "# Magnitude, DATE, MO, STARTING COUNTY,YR, WID,\n",
    "#STARTING COUNTy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9d138115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "\n",
    "target = 'MO'\n",
    "X = pd.get_dummies(df.drop(columns=target))\n",
    "\n",
    "\n",
    "# Create our target\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3203ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1f103",
   "metadata": {},
   "source": [
    "### Run through the Models Provided in the Module 17 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "76c76ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive random oversampling\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  3  0  0  0  0  2  0  3  0  0  2]\n",
      " [ 1  5  0  0  0  0  1  0  2  1  1  4]\n",
      " [ 2  8  1  0  2  0  2  0  3  2  0  0]\n",
      " [ 2 13  2  0  6  0 10  1 15  2  1  0]\n",
      " [ 7  3  0  0  3  0  5  0  9  1  1  3]\n",
      " [ 0  1  0  0  1  0  0  1  3  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  0  0]\n",
      " [ 1  1  0  0  1  0  2  0  4  1  0  1]\n",
      " [ 1  5  0  0  1  0  7  0  2  0  1  2]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0]]\n",
      "\n",
      "The accuracy score: \n",
      "0.056420363926344794\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.00      0.00      0.91      0.00      0.00      0.00        10\n",
      "          2       0.13      0.33      0.78      0.19      0.51      0.25        15\n",
      "          3       0.33      0.05      0.99      0.09      0.22      0.04        20\n",
      "          4       0.00      0.00      1.00      0.00      0.00      0.00        52\n",
      "          5       0.21      0.09      0.92      0.13      0.29      0.08        32\n",
      "          6       0.00      0.00      1.00      0.00      0.00      0.00         8\n",
      "          7       0.00      0.00      0.83      0.00      0.00      0.00         2\n",
      "          8       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.75      0.00      0.00      0.00         2\n",
      "         10       0.10      0.09      0.94      0.10      0.29      0.08        11\n",
      "         11       0.25      0.05      0.98      0.09      0.23      0.05        19\n",
      "         12       0.00      0.00      0.92      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.12      0.06      0.95      0.07      0.17      0.05       172\n",
      "\n",
      "SMOTE\n",
      "\n",
      "An Error as occured\n",
      "Random Under Sampler\n",
      "\n",
      "The accuracy score: \n",
      "0.10848647962882411\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  3  0  0  0  0  3  0  1]\n",
      " [ 1  2  0  2  4  1  3  0  0  2  0  0]\n",
      " [ 3  0  0  1  8  2  1  3  0  2  0  0]\n",
      " [11  1  0  0 13  6  2  5  0 13  0  1]\n",
      " [ 6  0  0  0  3  3  6  2  0  9  1  2]\n",
      " [ 1  0  0  0  1  2  1  0  0  3  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 3  0  0  0  1  2  1  0  0  4  0  0]\n",
      " [ 8  0  0  0  4  2  2  0  0  2  1  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.08      0.30      0.78      0.12      0.48      0.22        10\n",
      "          2       0.67      0.13      0.99      0.22      0.36      0.12        15\n",
      "          3       0.00      0.00      1.00      0.00      0.00      0.00        20\n",
      "          4       0.00      0.00      0.97      0.00      0.00      0.00        52\n",
      "          5       0.08      0.09      0.76      0.09      0.27      0.07        32\n",
      "          6       0.10      0.25      0.89      0.14      0.47      0.21         8\n",
      "          7       0.00      0.00      0.91      0.00      0.00      0.00         2\n",
      "          8       0.00      0.00      0.94      0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      1.00      0.00      0.00      0.00         2\n",
      "         10       0.10      0.36      0.78      0.16      0.53      0.27        11\n",
      "         11       0.50      0.05      0.99      0.10      0.23      0.05        19\n",
      "         12       0.00      0.00      0.98      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.14      0.09      0.91      0.07      0.19      0.07       172\n",
      "\n",
      "SMOTEENN\n",
      "\n",
      "An Error as occured\n",
      "Balanced Random Forest Classifier \n",
      "\n",
      "The accuracy score: \n",
      "0.4761512112289624\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  0  1  0  0  1  0  0  0  0  0  1]\n",
      " [ 0  9  0  0  0  0  0  1  1  1  0  3]\n",
      " [ 0  1 11  0  0  0  0  0  5  0  1  2]\n",
      " [ 1  8  4 19  2  0  1  1  5  4  0  7]\n",
      " [ 2  0  4  0 13  1  1  1  3  1  4  2]\n",
      " [ 0  0  1  2  1  2  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  1  0  0  0]\n",
      " [ 1  0  0  2  1  1  0  0  2  2  0  2]\n",
      " [ 1  0  1  0  1  1  0  0  0  1 13  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.58      0.70      0.97      0.64      0.82      0.66        10\n",
      "          2       0.50      0.60      0.94      0.55      0.75      0.55        15\n",
      "          3       0.50      0.55      0.93      0.52      0.71      0.49        20\n",
      "          4       0.83      0.37      0.97      0.51      0.59      0.33        52\n",
      "          5       0.72      0.41      0.96      0.52      0.63      0.37        32\n",
      "          6       0.29      0.25      0.97      0.27      0.49      0.22         8\n",
      "          7       0.00      0.00      0.99      0.00      0.00      0.00         2\n",
      "          8       0.00      0.00      0.98      0.00      0.00      0.00         0\n",
      "          9       0.05      0.50      0.89      0.09      0.67      0.43         2\n",
      "         10       0.22      0.18      0.96      0.20      0.42      0.16        11\n",
      "         11       0.72      0.68      0.97      0.70      0.81      0.64        19\n",
      "         12       0.05      1.00      0.89      0.10      0.94      0.90         1\n",
      "\n",
      "avg / total       0.63      0.45      0.96      0.50      0.65      0.41       172\n",
      "\n",
      "Easy Ensemble Classifier \n",
      "\n",
      "The accuracy score: \n",
      "0.2750447518988189\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 5  0  0  0  0  2  0  0  0  0  3]\n",
      " [ 0  6  1  0  0  5  0  3  0  0  0]\n",
      " [ 0  0  9  0  0 10  0  1  0  0  0]\n",
      " [ 0  0  0 19  3 18  0 11  0  0  1]\n",
      " [ 0  0  0  0  2 21  0  8  0  1  0]\n",
      " [ 0  0  0  0  0  6  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  4  0  5  2  0  0]\n",
      " [ 0  0  0  0  1  9  0  3  0  6  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       1.00      0.50      1.00      0.67      0.71      0.48        10\n",
      "          2       1.00      0.40      1.00      0.57      0.63      0.38        15\n",
      "          3       0.90      0.45      0.99      0.60      0.67      0.42        20\n",
      "          4       1.00      0.37      1.00      0.54      0.60      0.34        52\n",
      "          5       0.29      0.06      0.96      0.10      0.25      0.05        32\n",
      "          6       0.08      0.75      0.55      0.14      0.65      0.42         8\n",
      "          7       0.00      0.00      1.00      0.00      0.00      0.00         2\n",
      "          9       0.00      0.00      0.81      0.00      0.00      0.00         2\n",
      "         10       1.00      0.18      1.00      0.31      0.43      0.17        11\n",
      "         11       0.86      0.32      0.99      0.46      0.56      0.29        19\n",
      "         12       0.00      0.00      0.98      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.77      0.32      0.97      0.42      0.52      0.29       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x =\"An Error as occured\"\n",
    "try:\n",
    "\n",
    "    print(f\"naive random oversampling\\n\")\n",
    "# Resample the training data with the RandomOversampler\n",
    "\n",
    "    ros = RandomOverSampler(random_state=1)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "except:\n",
    "      print(x)\n",
    "\n",
    "\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "try:\n",
    "\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "\n",
    "# Resample the training data with SMOTE\n",
    "    print(f\"SMOTE\\n\")\n",
    "    X_resampled, y_resampled = SMOTE(random_state=1,\n",
    "    sampling_strategy='auto').fit_resample(\n",
    "       X_train, y_train)\n",
    "    Counter(y_resampled)\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "\n",
    "except:\n",
    "      print(x)\n",
    "# Resample the data using the ClusterCentroids resampler\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "# Resample the training data with SMOTE\n",
    "\n",
    "try: \n",
    "    print(f\"Random Under Sampler\\n\")\n",
    "    ros = RandomUnderSampler(random_state=1)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "    Counter(y_resampled)\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "except:\n",
    "      print(x)\n",
    "# Resample the training data with SMOTEENN\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "# YOUR CODE HERE\n",
    "try:\n",
    "    print(f\"SMOTEENN\\n\")\n",
    "    smote_enn = SMOTEENN(random_state=0)\n",
    "    X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "    Counter(y_resampled)\n",
    "    model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "except:  \n",
    "      print(x)\n",
    "\n",
    "\n",
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "try:\n",
    "    print(f\"Balanced Random Forest Classifier \\n\")\n",
    "    model = BalancedRandomForestClassifier(n_estimators =100, random_state=1)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    # Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "except:\n",
    "    print(x)\n",
    "\n",
    "# Train the EasyEnsembleClassifier\n",
    "try:\n",
    "    print(f\"Easy Ensemble Classifier \\n\")\n",
    "\n",
    "# Train the EasyEnsembleClassifier\n",
    "    from imblearn.ensemble import EasyEnsembleClassifier \n",
    "    model = EasyEnsembleClassifier(n_estimators =100, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "# Calculated the balanced accuracy score\n",
    "    y_pred = model.predict(X_test)\n",
    "    balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "    print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "    \n",
    "except:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39090f35",
   "metadata": {},
   "source": [
    "### Additional Machine Learning Models that we can try "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af4066",
   "metadata": {},
   "source": [
    "#### SGDClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24d694",
   "metadata": {},
   "source": [
    "link to reference: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cbeab8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.5333639347096285\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0 14  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0 17  2  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 51  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  6 25  1  0  0  0  0  0]\n",
      " [ 0  0  0  7  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  6  0  0  0  0  5  0  0]\n",
      " [ 0  0  0  3  0  0  0  0  0 16  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       1.00      0.90      1.00      0.95      0.95      0.89        10\n",
      "          2       1.00      0.93      1.00      0.97      0.97      0.93        15\n",
      "          3       1.00      0.85      1.00      0.92      0.92      0.84        20\n",
      "          4       0.62      0.98      0.74      0.76      0.85      0.74        52\n",
      "          5       0.96      0.78      0.99      0.86      0.88      0.76        32\n",
      "          6       0.33      0.12      0.99      0.18      0.35      0.11         8\n",
      "          7       0.00      0.00      1.00      0.00      0.00      0.00         2\n",
      "          9       0.00      0.00      1.00      0.00      0.00      0.00         2\n",
      "         10       1.00      0.45      1.00      0.62      0.67      0.43        11\n",
      "         11       1.00      0.84      1.00      0.91      0.92      0.83        19\n",
      "         12       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.82      0.80      0.92      0.79      0.83      0.72       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sklearn.linear_model.SGDClassifier\n",
    "\n",
    "\n",
    "# This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: \n",
    "#     the gradient of the loss is estimated each sample at a time and the model is updated \n",
    "#     along the way with a decreasing strength schedule (aka learning rate).\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "# X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "# Counter(y_resampled)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b755a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0adc0385",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da010d14",
   "metadata": {},
   "source": [
    "link to reference: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b701fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.4282403302439187\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 8  0  0  0  0  1  0  0  0  1  0  0]\n",
      " [ 0 12  0  0  0  1  1  1  0  0  0  0]\n",
      " [ 0  1  9  1  1  1  0  0  2  2  3  0]\n",
      " [ 2  2  1 38  0  4  0  2  0  1  1  1]\n",
      " [ 1  1  1  0 19  2  1  2  0  2  3  0]\n",
      " [ 0  0  1  2  0  2  2  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  1  0]\n",
      " [ 2  1  0  0  1  1  0  0  0  5  0  1]\n",
      " [ 1  0  0  0  0  3  1  1  0  1 12  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.57      0.80      0.96      0.67      0.88      0.76        10\n",
      "          2       0.71      0.80      0.97      0.75      0.88      0.76        15\n",
      "          3       0.75      0.45      0.98      0.56      0.66      0.42        20\n",
      "          4       0.93      0.73      0.97      0.82      0.84      0.70        52\n",
      "          5       0.86      0.59      0.98      0.70      0.76      0.56        32\n",
      "          6       0.13      0.25      0.92      0.17      0.48      0.21         8\n",
      "          7       0.00      0.00      0.96      0.00      0.00      0.00         2\n",
      "          8       0.00      0.00      0.97      0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.98      0.00      0.00      0.00         2\n",
      "         10       0.38      0.45      0.95      0.42      0.66      0.41        11\n",
      "         11       0.57      0.63      0.94      0.60      0.77      0.58        19\n",
      "         12       0.00      0.00      0.99      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.72      0.61      0.97      0.65      0.75      0.57       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# When performing classification you often want to predict not only the class label, \n",
    "# but also the associated probability. \n",
    "# This probability gives you some kind of confidence on the prediction\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)  # GaussianNB itself does not support sample-weights\n",
    "\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abcbe1e",
   "metadata": {},
   "source": [
    " RandomOverSampler: Using differnt solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c2db5",
   "metadata": {},
   "source": [
    "link to reference https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "412e4728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.48835934798853453\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 15  2  1  0  0  0  0  1  1  0]\n",
      " [ 0  1  3 36  4  3  0  1  1  0  1  2]\n",
      " [ 1  0  2  1 26  2  0  0  0  0  0  0]\n",
      " [ 0  0  2  2  1  2  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  0  0]\n",
      " [ 2  0  1  1  2  0  0  0  0  4  0  1]\n",
      " [ 0  1  0  0  1  3  0  0  0  0 14  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.75      0.90      0.98      0.82      0.94      0.88        10\n",
      "          2       0.87      0.87      0.99      0.87      0.93      0.85        15\n",
      "          3       0.58      0.75      0.93      0.65      0.83      0.68        20\n",
      "          4       0.84      0.69      0.94      0.76      0.81      0.64        52\n",
      "          5       0.68      0.81      0.91      0.74      0.86      0.74        32\n",
      "          6       0.20      0.25      0.95      0.22      0.49      0.22         8\n",
      "          7       0.00      0.00      0.99      0.00      0.00      0.00         2\n",
      "          8       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.99      0.00      0.00      0.00         2\n",
      "         10       0.80      0.36      0.99      0.50      0.60      0.34        11\n",
      "         11       0.88      0.74      0.99      0.80      0.85      0.71        19\n",
      "         12       0.00      0.00      0.98      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.72      0.69      0.95      0.70      0.79      0.64       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c995dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.48835934798853453\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 15  2  1  0  0  0  0  1  1  0]\n",
      " [ 0  1  3 36  4  3  0  1  1  0  1  2]\n",
      " [ 1  0  2  1 26  2  0  0  0  0  0  0]\n",
      " [ 0  0  2  2  1  2  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  0  0]\n",
      " [ 2  0  1  1  2  0  0  0  0  4  0  1]\n",
      " [ 0  1  0  0  1  3  0  0  0  0 14  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.75      0.90      0.98      0.82      0.94      0.88        10\n",
      "          2       0.87      0.87      0.99      0.87      0.93      0.85        15\n",
      "          3       0.58      0.75      0.93      0.65      0.83      0.68        20\n",
      "          4       0.84      0.69      0.94      0.76      0.81      0.64        52\n",
      "          5       0.68      0.81      0.91      0.74      0.86      0.74        32\n",
      "          6       0.20      0.25      0.95      0.22      0.49      0.22         8\n",
      "          7       0.00      0.00      0.99      0.00      0.00      0.00         2\n",
      "          8       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.99      0.00      0.00      0.00         2\n",
      "         10       0.80      0.36      0.99      0.50      0.60      0.34        11\n",
      "         11       0.88      0.74      0.99      0.80      0.85      0.71        19\n",
      "         12       0.00      0.00      0.98      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.72      0.69      0.95      0.70      0.79      0.64       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "45c88383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.09573748619801252\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  3  0  0  0  0  2  4  0  1  0]\n",
      " [ 0  6  0  0  0  0  3  3  0  3  0]\n",
      " [ 3  8  1  0  1  0  4  3  0  0  0]\n",
      " [ 2 13  1  1  5  0  7 19  3  1  0]\n",
      " [ 7  3  0  1  1  0  7 10  1  2  0]\n",
      " [ 0  1  0  0  1  0  1  3  2  0  0]\n",
      " [ 0  0  0  0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 1  1  0  0  1  0  2  6  0  0  0]\n",
      " [ 2  5  0  0  0  0  6  5  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.00      0.00      0.91      0.00      0.00      0.00        10\n",
      "          2       0.15      0.40      0.78      0.22      0.56      0.30        15\n",
      "          3       0.50      0.05      0.99      0.09      0.22      0.04        20\n",
      "          4       0.50      0.02      0.99      0.04      0.14      0.02        52\n",
      "          5       0.11      0.03      0.94      0.05      0.17      0.03        32\n",
      "          6       0.00      0.00      1.00      0.00      0.00      0.00         8\n",
      "          7       0.03      0.50      0.80      0.05      0.63      0.39         2\n",
      "          9       0.00      0.00      0.68      0.00      0.00      0.00         2\n",
      "         10       0.00      0.00      0.96      0.00      0.00      0.00        11\n",
      "         11       0.12      0.05      0.95      0.07      0.22      0.05        19\n",
      "         12       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.26      0.06      0.95      0.06      0.18      0.05       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = LogisticRegression(solver='sag', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9ccdda0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.5179541550953034\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 15  2  1  0  0  0  1  0  0  0]\n",
      " [ 0  1  4 38  4  3  0  1  0  0  0  1]\n",
      " [ 1  0  2  1 26  2  0  0  0  0  0  0]\n",
      " [ 0  0  2  2  1  2  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  0  0]\n",
      " [ 1  0  1  1  2  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  1  2  0  0  0  0 16  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.75      0.90      0.98      0.82      0.94      0.88        10\n",
      "          2       0.87      0.87      0.99      0.87      0.93      0.85        15\n",
      "          3       0.56      0.75      0.92      0.64      0.83      0.68        20\n",
      "          4       0.84      0.73      0.94      0.78      0.83      0.67        52\n",
      "          5       0.70      0.81      0.92      0.75      0.87      0.74        32\n",
      "          6       0.22      0.25      0.96      0.24      0.49      0.22         8\n",
      "          7       0.00      0.00      0.99      0.00      0.00      0.00         2\n",
      "          8       0.00      0.00      0.99      0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.99      0.00      0.00      0.00         2\n",
      "         10       1.00      0.55      1.00      0.71      0.74      0.52        11\n",
      "         11       1.00      0.84      1.00      0.91      0.92      0.83        19\n",
      "         12       0.00      0.00      0.99      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.75      0.73      0.95      0.73      0.82      0.68       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = LogisticRegression(solver='newton-cg', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4b3a7702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.09119203165255797\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  3  0  0  0  0  2  4  0  1  0]\n",
      " [ 0  6  0  0  0  0  3  3  0  3  0]\n",
      " [ 5  8  0  0  0  0  4  3  0  0  0]\n",
      " [ 6 13  1  1  1  0  7 19  2  2  0]\n",
      " [ 6  3  0  1  1  0  7 10  0  4  0]\n",
      " [ 1  1  0  0  0  0  1  3  2  0  0]\n",
      " [ 0  0  0  0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 2  1  0  0  0  0  2  6  0  0  0]\n",
      " [ 2  5  0  0  0  0  6  5  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.00      0.00      0.86      0.00      0.00      0.00        10\n",
      "          2       0.15      0.40      0.78      0.22      0.56      0.30        15\n",
      "          3       0.00      0.00      0.99      0.00      0.00      0.00        20\n",
      "          4       0.50      0.02      0.99      0.04      0.14      0.02        52\n",
      "          5       0.50      0.03      0.99      0.06      0.18      0.03        32\n",
      "          6       0.00      0.00      1.00      0.00      0.00      0.00         8\n",
      "          7       0.03      0.50      0.80      0.05      0.63      0.39         2\n",
      "          9       0.00      0.00      0.68      0.00      0.00      0.00         2\n",
      "         10       0.00      0.00      0.98      0.00      0.00      0.00        11\n",
      "         11       0.09      0.05      0.93      0.07      0.22      0.04        19\n",
      "         12       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.27      0.06      0.95      0.05      0.16      0.05       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = LogisticRegression(solver='saga', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bd225d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: \n",
      "0.5425025233936717\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 14  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0 17  0  1  1  0  0  0  1  0  0]\n",
      " [ 0  2  0 45  0  2  0  2  0  1  0  0]\n",
      " [ 2  0  1  0 25  1  0  1  0  0  2  0]\n",
      " [ 1  0  1  2  0  2  1  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  1  0]\n",
      " [ 3  0  1  0  1  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  1  2  0  0  0  0 16  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.60      0.90      0.96      0.72      0.93      0.86        10\n",
      "          2       0.82      0.93      0.98      0.87      0.96      0.91        15\n",
      "          3       0.81      0.85      0.97      0.83      0.91      0.82        20\n",
      "          4       0.94      0.87      0.97      0.90      0.92      0.83        52\n",
      "          5       0.89      0.78      0.98      0.83      0.87      0.75        32\n",
      "          6       0.25      0.25      0.96      0.25      0.49      0.22         8\n",
      "          7       0.00      0.00      0.99      0.00      0.00      0.00         2\n",
      "          8       0.00      0.00      0.98      0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.99      0.00      0.00      0.00         2\n",
      "         10       0.75      0.55      0.99      0.63      0.73      0.51        11\n",
      "         11       0.76      0.84      0.97      0.80      0.90      0.80        19\n",
      "         12       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.79      0.78      0.98      0.78      0.85      0.75       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "# Train the Logistic Regression model using the resampled data\n",
    "\n",
    "model = make_pipeline(StandardScaler(),LogisticRegression(solver='newton-cg'))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# model = LogisticRegression(solver='newton-cg', random_state=1)\n",
    "    \n",
    "#'liblinear’, ‘sag’, ‘saga\n",
    "model.fit(X_resampled, y_resampled)\n",
    "# Display the confusion matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361402a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b4195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a37fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
