{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a2e5fa",
   "metadata": {},
   "source": [
    "## import the data from the database "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e2798",
   "metadata": {},
   "source": [
    "This is my attempt to make a connection between the postgres database and this file\n",
    "It seems to work up until the import config from config portion \n",
    "I'm not sure if I don't have my environment set up correctly or what the issue is \n",
    "but it is needed because the program will recognize the class we are trying to use as \n",
    "a module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e74a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the password from a seperate file that is ignored on github\n",
    "# from config import password\n",
    "# import dependencies \n",
    "import psycopg2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab83a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass \n",
    "password = getpass ('Enter database password')\n",
    "\n",
    "try: \n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        database = \"Tennessee_Tornadoes\",\n",
    "        user=\"postgres\",\n",
    "        password=password)\n",
    "    print ('pyscopg2 connection:', conn)\n",
    "    \n",
    "except Exception as err:\n",
    "    print ('psycopg2 connect() ERROR:', err)\n",
    "    connect = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a888f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = conn.cursor()\n",
    "cr.execute('SELECT * FROM cleaned_tn_tornadoes;')\n",
    "tmp = cr.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390df315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the  column names\n",
    "col_names = []\n",
    "for db in cr.description:\n",
    "    col_names.append(db[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b3a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe, passing in the list of col_names extracted from the description\n",
    "df = pd.DataFrame(tmp, columns=col_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e911e5dd",
   "metadata": {},
   "source": [
    "### Run the first model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8cb22d",
   "metadata": {},
   "source": [
    "target = loss\n",
    "\n",
    "yields approx 55% accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc92d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataframe \n",
    "\n",
    "df_3 = df.drop(['Unnamed: 0','Unnamed: 0.1','TIME',\"WID\",\"starting county\",\n",
    "              'SLAT','SLON','ELAT','ELON','LEN','ending county','FID'], axis=1)\n",
    "df.columns\n",
    "\n",
    "\n",
    "target = 'Property Loss'\n",
    "X = pd.get_dummies(df_3.drop([target],axis = 1))\n",
    "\n",
    "\n",
    "# Create our target\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1)\n",
    "\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    PolynomialCountSketch(degree=2, n_components=300),\n",
    "    LogisticRegression(max_iter=1000),\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad7f03",
   "metadata": {},
   "source": [
    "### Run the second model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d62b32",
   "metadata": {},
   "source": [
    "target = Month \n",
    "\n",
    "yields approx 54% accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3928da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn.linear_model.SGDClassifier\n",
    "\n",
    "df_1 = df.drop(['Unnamed: 0','Unnamed: 0.1','TIME',\n",
    "              'SLAT','SLON','ELAT','ELON','LEN','ending county','Injuries','FID'], axis=1)\n",
    "# Create our features\n",
    "\n",
    "target = 'MO'\n",
    "X = pd.get_dummies(df_1.drop(columns=target))\n",
    "\n",
    "\n",
    "# Create our target\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1)\n",
    "\n",
    "model = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")\n",
    "# Display the confusion matrix\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\\n\")\n",
    "# Print the imbalanced classification report\n",
    "print(f\"Classification Report:\\n{classification_report_imbalanced(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d28cf0",
   "metadata": {},
   "source": [
    "### Run the third model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9667ffa8",
   "metadata": {},
   "source": [
    "target = Magnitude \n",
    "\n",
    "\n",
    "yields approx 59% accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c862ae9",
   "metadata": {},
   "source": [
    "Prepare the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep Date, Starting county, property loss and mag\n",
    "\n",
    "df_2 = df.drop([ 'MO','Unnamed: 0','Unnamed: 0.1','YR','TIME',\n",
    "              'SLAT','SLON','ELAT','ELON','LEN','ending county','starting county','Injuries','Fatalities','FID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae57f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "\n",
    "target = 'MAG'\n",
    "X = pd.get_dummies(df_2.drop(columns=target))\n",
    "\n",
    "\n",
    "# Create our target\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1)\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    MinMaxScaler(),\n",
    "    PolynomialCountSketch(degree=2, n_components=300),\n",
    "    LogisticRegression(),\n",
    ")\n",
    "\n",
    "pipe.fit(X_resampled, y_resampled).score(X_resampled, y_resampled)\n",
    "print(f\"The accuracy score: \\n{balanced_accuracy_score(y_test, y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c5182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39322090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
